import pandas as pd
import re
import requests
import uuid
import os
from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from io import BytesIO

app = FastAPI()

# æŒ‚è½½é™æ€ç›®å½•
os.makedirs("static", exist_ok=True)
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
def read_root():
    return {"message": "Service is running! All systems go."}

# ==========================================
# ğŸšª ç¬¬ä¸€æ‰‡é—¨ï¼šå¤„ç†ã€ä¹¦å•ã€‘æ ¼å¼ (process_excel)
# ==========================================
@app.post("/process")
async def process_excel(request: Request):
    data = await request.json()
    file_url = data.get('file_url')
    
    if not file_url:
        return {"error": "No file_url provided"}
    
    try:
        response = requests.get(file_url)
        response.raise_for_status()
        file_content = BytesIO(response.content)
        
        # è¯»å– Excel
        df = pd.read_excel(file_content, sheet_name='Sheet1')
        
        # æ•°æ®æ¸…æ´—
        new_columns = ['åºå·', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'ä¹¦å·', 'ä½¿ç”¨ç­çº§']
        df_clean = df.copy()
        if len(df_clean.columns) >= len(new_columns):
            df_clean.columns = new_columns
        else:
            df_clean = df_clean.iloc[:, :5]
            df_clean.columns = new_columns
        
        df_clean = df_clean.drop(0).reset_index(drop=True)
        
        def parse_class_info(class_str):
            classes = []
            pattern = r'(\d{2}[^ï¼ˆ\s]+?)ï¼ˆ(\d+)äºº?ï¼‰'
            matches = re.findall(pattern, str(class_str))
            for match in matches:
                classes.append((match[0], int(match[1])))
            
            pattern2 = r'(\d{2}[^ï¼ˆ\s]+?)ï¼ˆ(\d+)ï¼‰'
            matches2 = re.findall(pattern2, str(class_str))
            for match in matches2:
                if not any(c[0] == match[0] for c in classes):
                    classes.append((match[0], int(match[1])))
            return classes
        
        processed_data = []
        for index, row in df_clean.iterrows():
            classes = parse_class_info(str(row['ä½¿ç”¨ç­çº§']))
            for class_name, student_count in classes:
                processed_data.append({
                    'æ•™æåç§°': row['æ•™æåç§°'],
                    'å‡ºç‰ˆç¤¾': row['å‡ºç‰ˆç¤¾'],
                    'ä¹¦å·': row['ä¹¦å·'],
                    'ç­çº§': class_name,
                    'äººæ•°': student_count
                })
        
        result_df = pd.DataFrame(processed_data)
        if result_df.empty:
            return {"error": "No valid data extracted"}

        # æ ‡å‡†åŒ–å‡½æ•°
        def normalize_class_name_final(class_name):
            if 'äººï¼‰' in class_name or 'ï¼‰' in class_name:
                match = re.search(r'(2[45][^ï¼ˆï¼‰\s]+)', class_name)
                if match: return match.group(1)
            if 'çº§' in class_name and class_name.startswith(('24', '25')):
                year = class_name[:2]
                major = class_name[3:]
                if major.startswith('çº§'): major = major[1:]
                return year + major
            return class_name

        result_df['æ ‡å‡†åŒ–ç­çº§'] = result_df['ç­çº§'].apply(normalize_class_name_final)
        result_df_unique = result_df.drop_duplicates(subset=['æ ‡å‡†åŒ–ç­çº§', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'ä¹¦å·']).copy()
        
        result_df_unique['å¹´ä»½'] = result_df_unique['æ ‡å‡†åŒ–ç­çº§'].str[:2]
        result_df_unique['ä¸“ä¸šç­çº§'] = result_df_unique['æ ‡å‡†åŒ–ç­çº§'].str[2:]
        result_df_sorted = result_df_unique.sort_values(['å¹´ä»½', 'ä¸“ä¸šç­çº§'], ascending=[False, True])
        
        unique_classes_sorted = result_df_sorted['æ ‡å‡†åŒ–ç­çº§'].drop_duplicates().tolist()
        class_numbers = {name: i for i, name in enumerate(unique_classes_sorted, 1)}
        result_df_sorted['åºå·'] = result_df_sorted['æ ‡å‡†åŒ–ç­çº§'].map(class_numbers)
        
        final_df = result_df_sorted[['åºå·', 'æ ‡å‡†åŒ–ç­çº§', 'ä¹¦å·', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'äººæ•°']].copy()
        final_df = final_df.rename(columns={'æ ‡å‡†åŒ–ç­çº§': 'ç­çº§', 'æ•™æåç§°': 'ä¹¦å'})
        
        filename = f"result_{uuid.uuid4()}.xlsx"
        save_path = os.path.join("static", filename)
        final_df.to_excel(save_path, index=False)
        
        base_url = str(request.base_url).rstrip("/")
        download_url = f"{base_url}/static/{filename}"
        if download_url.startswith("http://"):
            download_url = download_url.replace("http://", "https://", 1)
        
        return {"download_url": download_url, "message": "success"}
    
    except Exception as e:
        return {"error": str(e)}

# ==========================================
# ğŸšª ç¬¬äºŒæ‰‡é—¨ï¼šå¤„ç†ã€å¯’å‡ä½œä¸šã€‘æ ¼å¼ (process_winter_homework)
# ==========================================
@app.post("/process_winter_homework")  # <--- æ‚¨ä¹‹å‰æ¼äº†è¿™ä¸€è¡Œï¼
async def process_winter_homework(request: Request):
    data = await request.json()
    file_url = data.get('file_url')
    if not file_url:
        return {"error": "è¯·æä¾›æ–‡ä»¶é“¾æ¥"}

    try:
        response = requests.get(file_url)
        file_content = BytesIO(response.content)
        
        # è¯»å– Excel
        df = pd.read_excel(file_content, sheet_name='Sheet1')

        # æ¸…ç†æ•°æ®
        new_columns = ['åºå·', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'ä¹¦å·', 'ä½¿ç”¨ç­çº§']
        df_clean = df.copy()
        if len(df_clean.columns) >= 5:
            df_clean = df_clean.iloc[:, :5]
        df_clean.columns = new_columns
        df_clean = df_clean.drop(0).reset_index(drop=True)

        # å®šä¹‰è§£æå‡½æ•°
        def parse_class_info_new(class_str):
            classes = []
            s = str(class_str)
            pattern = r'(\d+ç­)\s*(\d+)äºº'
            matches = re.findall(pattern, s)
            for match in matches:
                classes.append((match[0], int(match[1])))
            
            if not classes:
                pattern2 = r'(\d+ç­)\s*(\d+)'
                matches2 = re.findall(pattern2, s)
                for match in matches2:
                    classes.append((match[0], int(match[1])))
            return classes

        processed_data = []
        for index, row in df_clean.iterrows():
            textbook_name = row['æ•™æåç§°']
            publisher = row['å‡ºç‰ˆç¤¾']
            isbn = row['ä¹¦å·']
            class_info = row['ä½¿ç”¨ç­çº§']
            
            if pd.isna(class_info) or str(class_info).strip() == '':
                continue
            
            classes = parse_class_info_new(class_info)
            for class_name, student_count in classes:
                processed_data.append({
                    'æ•™æåç§°': textbook_name,
                    'å‡ºç‰ˆç¤¾': publisher,
                    'ä¹¦å·': isbn,
                    'ç­çº§': class_name,
                    'äººæ•°': student_count
                })

        result_df = pd.DataFrame(processed_data)
        if result_df.empty:
            return {"error": "æœªèƒ½è§£æå‡ºæœ‰æ•ˆæ•°æ®"}

        # æ’åºä¸ç¼–å·
        result_df['ç­çº§ç¼–å·æ•°å­—'] = result_df['ç­çº§'].astype(str).str.replace('ç­', '', regex=False)
        result_df = result_df[result_df['ç­çº§ç¼–å·æ•°å­—'].str.isnumeric()] 
        result_df['ç­çº§ç¼–å·æ•°å­—'] = result_df['ç­çº§ç¼–å·æ•°å­—'].astype(int)

        result_df_sorted = result_df.sort_values('ç­çº§ç¼–å·æ•°å­—', ascending=True)
        result_df_unique = result_df_sorted.drop_duplicates(subset=['ç­çº§', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'ä¹¦å·']).copy()

        unique_classes_sorted = result_df_unique['ç­çº§'].drop_duplicates().tolist()
        class_numbers = {name: i for i, name in enumerate(unique_classes_sorted, 1)}
        result_df_unique['ç¼–å·'] = result_df_unique['ç­çº§'].map(class_numbers)

        final_df = result_df_unique[['ç¼–å·', 'ç­çº§', 'äººæ•°', 'æ•™æåç§°', 'å‡ºç‰ˆç¤¾', 'ä¹¦å·']].reset_index(drop=True)

        # ä¿å­˜ä¸è¿”å›
        filename = f"winter_hw_{uuid.uuid4()}.xlsx"
        save_path = os.path.join("static", filename)
        final_df.to_excel(save_path, index=False)

        base_url = str(request.base_url).rstrip("/")
        download_url = f"{base_url}/static/{filename}"
        if download_url.startswith("http://"):
            download_url = download_url.replace("http://", "https://", 1)

        return {"download_url": download_url, "message": "å¯’å‡ä½œä¸šå¤„ç†å®Œæˆ"}

    except Exception as e:
        return {"error": f"å¤„ç†å‡ºé”™: {str(e)}"}
